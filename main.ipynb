{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching: Emerging trends, AI adoption, and regulatory standards in the Automotive industry (2024)\n",
      "Searching: Ford strategic focus areas and goals\n",
      "Searching: Top competitors of Ford in Automotive industry\n",
      "Searching: Applications of GenAI, LLMs, and automation in Automotive industry\n",
      "Searching: Key offerings and services by Ford\n",
      "Searching: Vision, mission, and product details for Ford in the Automotive industry\n",
      "Research summary saved to Ford_research_summary.md\n",
      "Use cases saved to Ford_use_cases.md\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class ResearchAgent:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://serpapi.com/search\"  # SerpApi base URL\n",
    "    \n",
    "    def search(self, query, num_results=10):\n",
    "        \"\"\"\n",
    "        Perform a search query using SerpApi.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"api_key\": self.api_key,\n",
    "            \"num\": num_results,\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json()  # Return the search results\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def gather_data(self, company_name, industry):\n",
    "        \"\"\"\n",
    "        Gather data about the company and its industry.\n",
    "        \"\"\"\n",
    "        queries = {\n",
    "            \"industry_trends\": f\"Emerging trends, AI adoption, and regulatory standards in the {industry} industry (2024)\",\n",
    "            \"company_focus\": f\"{company_name} strategic focus areas and goals\",\n",
    "            \"competitor_analysis\": f\"Top competitors of {company_name} in {industry} industry\",\n",
    "            \"technology_integration\": f\"Applications of GenAI, LLMs, and automation in {industry} industry\",\n",
    "            \"key_offerings\": f\"Key offerings and services by {company_name}\",\n",
    "            \"vision_and_product_info\": f\"Vision, mission, and product details for {company_name} in the {industry} industry\",\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for key, query in queries.items():\n",
    "            print(f\"Searching: {query}\")\n",
    "            results[key] = self.search(query)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def generate_summary(self, data):\n",
    "        \"\"\"\n",
    "        Generate a summary from the gathered data.\n",
    "        \"\"\"\n",
    "        summary = []\n",
    "        for key, result in data.items():\n",
    "            if not result:\n",
    "                summary.append(f\"No results found for {key.replace('_', ' ').title()}.\")\n",
    "                continue\n",
    "            summary.append(f\"### {key.replace('_', ' ').title()} ###\")\n",
    "            for i, item in enumerate(result.get(\"organic_results\", []), start=1):\n",
    "                title = item.get(\"title\", \"No Title\")\n",
    "                link = item.get(\"link\", \"No Link\")\n",
    "                snippet = item.get(\"snippet\", \"No Snippet\")\n",
    "                summary.append(f\"{i}. **{title}**\\n   {snippet}\\n   [Read more]({link})\\n\")\n",
    "        \n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "    def propose_use_cases(self, data, company_name, industry):\n",
    "        \"\"\"\n",
    "        Propose relevant use cases based on the analyzed data.\n",
    "        \"\"\"\n",
    "        use_cases = [f\"# Suggested Use Cases for {company_name} in the {industry} Industry\\n\"]\n",
    "        \n",
    "        trends = data.get(\"industry_trends\", {}).get(\"organic_results\", [])\n",
    "        tech_integration = data.get(\"technology_integration\", {}).get(\"organic_results\", [])\n",
    "        key_offerings = data.get(\"key_offerings\", {}).get(\"organic_results\", [])\n",
    "        \n",
    "        if trends:\n",
    "            use_cases.append(\"## Industry Trends and Standards Insights\\n\")\n",
    "            for item in trends[:3]:  # Include top 3 trends\n",
    "                use_cases.append(f\"- {item.get('title', 'Trend')}: {item.get('snippet', 'No description available')}\")\n",
    "\n",
    "        if key_offerings:\n",
    "            use_cases.append(\"\\n## Key Offerings\\n\")\n",
    "            for item in key_offerings[:3]:  # Include top 3 key offerings\n",
    "                use_cases.append(f\"- {item.get('title', 'Offering')}: {item.get('snippet', 'No description available')}\")\n",
    "\n",
    "        use_cases.append(\"\\n## Proposed Use Cases\\n\")\n",
    "        if tech_integration:\n",
    "            use_cases.append(\"### Leveraging AI, ML, and Automation\\n\")\n",
    "            for item in tech_integration[:3]:  # Include top 3 use cases\n",
    "                use_cases.append(f\"- {item.get('title', 'Use Case')}: {item.get('snippet', 'No description available')}\")\n",
    "        else:\n",
    "            use_cases.append(\"- Automate repetitive tasks using RPA and AI-driven workflows.\\n\")\n",
    "            use_cases.append(\"- Enhance customer satisfaction through personalized chatbots powered by GenAI.\\n\")\n",
    "            use_cases.append(\"- Implement predictive analytics for maintenance and inventory optimization.\\n\")\n",
    "        \n",
    "        return \"\\n\".join(use_cases)\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'your_serpapi_key_here' with your SerpApi key\n",
    "    api_key = \"5402a7bfd62fcf4fa0b44ea525ce9b7093938358b0c62f86757ee96f82b6815e\"\n",
    "    agent = ResearchAgent(api_key)\n",
    "    \n",
    "    # Ask user for company and industry details\n",
    "    company_name = input(\"Enter the company name: \").strip()\n",
    "    industry = input(\"Enter the industry: \").strip()\n",
    "    \n",
    "    # Gather data\n",
    "    research_data = agent.gather_data(company_name, industry)\n",
    "    \n",
    "    # Generate a summary report\n",
    "    summary_report = agent.generate_summary(research_data)\n",
    "    output_file = f\"{company_name}_research_summary.md\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(summary_report)\n",
    "    print(f\"Research summary saved to {output_file}\")\n",
    "    \n",
    "    # Propose relevant use cases\n",
    "    use_case_report = agent.propose_use_cases(research_data, company_name, industry)\n",
    "    use_case_file = f\"{company_name}_use_cases.md\"\n",
    "    with open(use_case_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(use_case_report)\n",
    "    print(f\"Use cases saved to {use_case_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fine-tuning the model: 'Groq' object has no attribute 'train_model'\n",
      "Ask me questions about leveraging GenAI, LLMs, and ML technologies.\n",
      "Model not fine-tuned. Please check the training process.\n",
      "Answer: None\n",
      "Model not fine-tuned. Please check the training process.\n",
      "Answer: None\n",
      "Model not fine-tuned. Please check the training process.\n",
      "Answer: None\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "class GenAIQuerySystem:\n",
    "    def __init__(self, folder_path):\n",
    "        \"\"\"\n",
    "        Initialize the GenAI Query System by loading all text files from the specified folder.\n",
    "        Then, initialize the Groq API client.\n",
    "        \"\"\"\n",
    "        load_dotenv()  # Load environment variables from the .env file\n",
    "        groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        if not groq_api_key:\n",
    "            raise ValueError(\"Groq API Key not found. Please set GROQ_API_KEY in your .env file.\")\n",
    "        \n",
    "        self.groq_client = Groq(api_key=groq_api_key)\n",
    "        self.context = self.load_context_from_folder(folder_path)\n",
    "        \n",
    "        # Fine-tuning model using your dataset\n",
    "        self.model = self.fine_tune_model(self.context)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_context_from_folder(folder_path):\n",
    "        \"\"\"\n",
    "        Load and combine all text content from files in the specified folder.\n",
    "        \"\"\"\n",
    "        combined_context = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        combined_context.append(f.read())\n",
    "        return \"\\n\".join(combined_context)\n",
    "\n",
    "    def fine_tune_model(self, context):\n",
    "        \"\"\"\n",
    "        Fine-tune a Groq model using the provided context data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            fine_tuned_model = self.groq_client.train_model(data=context, task=\"text-generation\")\n",
    "            return fine_tuned_model\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fine-tuning the model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def answer_question(self, question):\n",
    "        \"\"\"\n",
    "        Answer a question using the fine-tuned Groq model and the loaded context.\n",
    "        \"\"\"\n",
    "        if self.model:\n",
    "            try:\n",
    "                response = self.groq_client.query_model(model=self.model, query=question, context=self.context)\n",
    "                return response['answer']\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while answering the question: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Model not fine-tuned. Please check the training process.\")\n",
    "            return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the folder containing training data\n",
    "    folder_path = \"results\"\n",
    "    try:\n",
    "        gen_ai_system = GenAIQuerySystem(folder_path)\n",
    "\n",
    "        print(\"Ask me questions about leveraging GenAI, LLMs, and ML technologies.\")\n",
    "        while True:\n",
    "            question = input(\"\\nYour question (type 'exit' to quit): \").strip()\n",
    "            if question.lower() == \"exit\":\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            try:\n",
    "                answer = gen_ai_system.answer_question(question)\n",
    "                print(f\"Answer: {answer}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing industry_trends...\n",
      "Analyzing company_focus...\n",
      "Analyzing competitor_analysis...\n",
      "Finding resources for: Implement automation for repetitive tasks.\n",
      "Finding resources for: Develop predictive models for key business metrics.\n",
      "Finding resources for: Use AI for supply chain optimization.\n",
      "Finding resources for: Build a customer service chatbot to enhance engagement.\n",
      "Use case report saved to use_case_report.md\n"
     ]
    }
   ],
   "source": [
    "class UseCaseGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def analyze_data(self, research_data):\n",
    "        \"\"\"\n",
    "        Analyze research data to identify patterns and opportunities.\n",
    "        \"\"\"\n",
    "        use_cases = []\n",
    "        if not research_data:\n",
    "            print(\"No research data provided.\")\n",
    "            return []\n",
    "\n",
    "        # Example use case generation based on keywords in research data\n",
    "        for key, result in research_data.items():\n",
    "            if not result:\n",
    "                continue\n",
    "\n",
    "            print(f\"Analyzing {key}...\")\n",
    "            for item in result.get(\"organic_results\", []):\n",
    "                snippet = item.get(\"snippet\", \"\").lower()\n",
    "\n",
    "                # Identify potential use cases based on common keywords\n",
    "                if \"automation\" in snippet:\n",
    "                    use_cases.append(\"Implement automation for repetitive tasks.\")\n",
    "                if \"predictive\" in snippet:\n",
    "                    use_cases.append(\"Develop predictive models for key business metrics.\")\n",
    "                if \"customer\" in snippet:\n",
    "                    use_cases.append(\"Build a customer service chatbot to enhance engagement.\")\n",
    "                if \"supply chain\" in snippet:\n",
    "                    use_cases.append(\"Use AI for supply chain optimization.\")\n",
    "\n",
    "        return list(set(use_cases))  # Return unique use cases\n",
    "\n",
    "    def find_resources(self, use_cases):\n",
    "        \"\"\"\n",
    "        Search for relevant datasets and tools for each use case.\n",
    "        \"\"\"\n",
    "        resources = {}\n",
    "        for use_case in use_cases:\n",
    "            print(f\"Finding resources for: {use_case}\")\n",
    "\n",
    "            # Example resource mapping\n",
    "            if \"automation\" in use_case:\n",
    "                resources[use_case] = {\n",
    "                    \"datasets\": [\"https://www.kaggle.com/datasets\"],\n",
    "                    \"tools\": [\"https://www.uipath.com/\", \"https://airflow.apache.org/\"],\n",
    "                }\n",
    "            elif \"predictive\" in use_case:\n",
    "                resources[use_case] = {\n",
    "                    \"datasets\": [\"https://www.kaggle.com/datasets/gpred/predictive-maintenance\"],\n",
    "                    \"tools\": [\"https://www.tensorflow.org/\", \"https://scikit-learn.org/\"],\n",
    "                }\n",
    "            elif \"customer service\" in use_case:\n",
    "                resources[use_case] = {\n",
    "                    \"datasets\": [\"https://www.huggingface.co/datasets/daily_dialog\"],\n",
    "                    \"tools\": [\"https://dialogflow.cloud.google.com/\", \"https://rasa.com/\"],\n",
    "                }\n",
    "            elif \"supply chain\" in use_case:\n",
    "                resources[use_case] = {\n",
    "                    \"datasets\": [\"https://data.world/datasets/supply-chain\"],\n",
    "                    \"tools\": [\"https://www.anylogistix.com/\", \"https://or-tools.github.io/\"],\n",
    "                }\n",
    "\n",
    "        return resources\n",
    "\n",
    "    def generate_report(self, use_cases, resources):\n",
    "        \"\"\"\n",
    "        Create a detailed report with use cases and their resources.\n",
    "        \"\"\"\n",
    "        report = [\"# AI/ML Use Cases and Resources\\n\"]\n",
    "        for use_case in use_cases:\n",
    "            report.append(f\"## Use Case: {use_case}\\n\")\n",
    "            resource = resources.get(use_case, {})\n",
    "            datasets = resource.get(\"datasets\", [])\n",
    "            tools = resource.get(\"tools\", [])\n",
    "\n",
    "            report.append(\"### Datasets:\\n\")\n",
    "            report.extend([f\"- [{url}]({url})\\n\" for url in datasets])\n",
    "\n",
    "            report.append(\"\\n### Tools:\\n\")\n",
    "            report.extend([f\"- [{url}]({url})\\n\" for url in tools])\n",
    "\n",
    "            report.append(\"\\n---\\n\")\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume `research_data` is the output from the previous ResearchAgent step\n",
    "    with open(\"research_summary.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "        research_summary = file.read()\n",
    "    \n",
    "    # Convert the research summary into dummy structured data for demo purposes\n",
    "    # (Replace this with the actual JSON output from the `ResearchAgent`)\n",
    "    research_data = {\n",
    "        \"industry_trends\": {\n",
    "            \"organic_results\": [{\"snippet\": \"AI automation is revolutionizing the supply chain in 2024.\"}],\n",
    "        },\n",
    "        \"company_focus\": {\n",
    "            \"organic_results\": [{\"snippet\": \"Tesla focuses on predictive maintenance for vehicles.\"}],\n",
    "        },\n",
    "        \"competitor_analysis\": {\n",
    "            \"organic_results\": [{\"snippet\": \"Competitors are using AI chatbots for customer service.\"}],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    generator = UseCaseGenerator()\n",
    "\n",
    "    # Generate use cases\n",
    "    use_cases = generator.analyze_data(research_data)\n",
    "\n",
    "    # Find resources for the use cases\n",
    "    resources = generator.find_resources(use_cases)\n",
    "\n",
    "    # Generate a report\n",
    "    report = generator.generate_report(use_cases, resources)\n",
    "\n",
    "    # Save the report to a markdown file\n",
    "    with open(\"use_case_report.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(report)\n",
    "\n",
    "    print(\"Use case report saved to use_case_report.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Implement automation for repetitive tasks.\n",
      "Evaluating: Develop predictive models for key business metrics.\n",
      "Evaluating: Build a customer service chatbot to enhance engagement.\n",
      "Evaluating: Use AI for supply chain optimization.\n",
      "Action plan saved to action_plan.md\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "class ActionPlanGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def prioritize_use_cases(self, use_cases):\n",
    "        \"\"\"\n",
    "        Prioritize use cases based on potential impact and feasibility.\n",
    "        \"\"\"\n",
    "        priorities = {}\n",
    "        for use_case in use_cases:\n",
    "            print(f\"Evaluating: {use_case}\")\n",
    "\n",
    "            # Dummy prioritization logic (can be replaced with real criteria)\n",
    "            if \"automation\" in use_case:\n",
    "                priorities[use_case] = {\"priority\": \"High\", \"estimated_timeline\": \"3 months\"}\n",
    "            elif \"predictive\" in use_case:\n",
    "                priorities[use_case] = {\"priority\": \"Medium\", \"estimated_timeline\": \"4 months\"}\n",
    "            elif \"customer service\" in use_case:\n",
    "                priorities[use_case] = {\"priority\": \"High\", \"estimated_timeline\": \"2 months\"}\n",
    "            elif \"supply chain\" in use_case:\n",
    "                priorities[use_case] = {\"priority\": \"Medium\", \"estimated_timeline\": \"5 months\"}\n",
    "            else:\n",
    "                priorities[use_case] = {\"priority\": \"Low\", \"estimated_timeline\": \"6+ months\"}\n",
    "\n",
    "        return priorities\n",
    "\n",
    "    def generate_action_plan(self, use_cases, resources, priorities):\n",
    "        \"\"\"\n",
    "        Create an action plan for implementing the use cases.\n",
    "        \"\"\"\n",
    "        action_plan = [\"# Action Plan for AI/ML Implementation\\n\"]\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        for use_case in use_cases:\n",
    "            priority_info = priorities.get(use_case, {})\n",
    "            resources_info = resources.get(use_case, {})\n",
    "            datasets = resources_info.get(\"datasets\", [])\n",
    "            tools = resources_info.get(\"tools\", [])\n",
    "\n",
    "            action_plan.append(f\"## Use Case: {use_case}\\n\")\n",
    "            action_plan.append(f\"**Priority:** {priority_info.get('priority', 'Unknown')}\\n\")\n",
    "            action_plan.append(f\"**Estimated Timeline:** {priority_info.get('estimated_timeline', 'Unknown')}\\n\")\n",
    "            action_plan.append(f\"**Start Date:** {today.strftime('%Y-%m-%d')}\\n\")\n",
    "\n",
    "            action_plan.append(\"\\n### Resources:\\n\")\n",
    "            action_plan.append(\"#### Datasets:\\n\")\n",
    "            action_plan.extend([f\"- [{url}]({url})\\n\" for url in datasets])\n",
    "\n",
    "            action_plan.append(\"\\n#### Tools:\\n\")\n",
    "            action_plan.extend([f\"- [{url}]({url})\\n\" for url in tools])\n",
    "\n",
    "            action_plan.append(\"\\n---\\n\")\n",
    "\n",
    "        return \"\\n\".join(action_plan)\n",
    "\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Use cases and resources from the previous step\n",
    "    use_cases = [\n",
    "        \"Implement automation for repetitive tasks.\",\n",
    "        \"Develop predictive models for key business metrics.\",\n",
    "        \"Build a customer service chatbot to enhance engagement.\",\n",
    "        \"Use AI for supply chain optimization.\",\n",
    "    ]\n",
    "\n",
    "    resources = {\n",
    "        \"Implement automation for repetitive tasks.\": {\n",
    "            \"datasets\": [\"https://www.kaggle.com/datasets\"],\n",
    "            \"tools\": [\"https://www.uipath.com/\", \"https://airflow.apache.org/\"],\n",
    "        },\n",
    "        \"Develop predictive models for key business metrics.\": {\n",
    "            \"datasets\": [\"https://www.kaggle.com/datasets/gpred/predictive-maintenance\"],\n",
    "            \"tools\": [\"https://www.tensorflow.org/\", \"https://scikit-learn.org/\"],\n",
    "        },\n",
    "        \"Build a customer service chatbot to enhance engagement.\": {\n",
    "            \"datasets\": [\"https://www.huggingface.co/datasets/daily_dialog\"],\n",
    "            \"tools\": [\"https://dialogflow.cloud.google.com/\", \"https://rasa.com/\"],\n",
    "        },\n",
    "        \"Use AI for supply chain optimization.\": {\n",
    "            \"datasets\": [\"https://data.world/datasets/supply-chain\"],\n",
    "            \"tools\": [\"https://www.anylogistix.com/\", \"https://or-tools.github.io/\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Initialize the action plan generator\n",
    "    generator = ActionPlanGenerator()\n",
    "\n",
    "    # Prioritize use cases\n",
    "    priorities = generator.prioritize_use_cases(use_cases)\n",
    "\n",
    "    # Generate an action plan\n",
    "    action_plan = generator.generate_action_plan(use_cases, resources, priorities)\n",
    "\n",
    "    # Save the action plan to a markdown file\n",
    "    with open(\"action_plan.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(action_plan)\n",
    "\n",
    "    print(\"Action plan saved to action_plan.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review report saved to review_report.md\n"
     ]
    }
   ],
   "source": [
    "class ReviewReportGenerator:\n",
    "    def __init__(self, action_plan_file):\n",
    "        self.action_plan_file = action_plan_file\n",
    "\n",
    "    def extract_highlights(self):\n",
    "        \"\"\"\n",
    "        Extract key highlights from the action plan.\n",
    "        \"\"\"\n",
    "        highlights = []\n",
    "        with open(self.action_plan_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith(\"## Use Case:\"):\n",
    "                    highlights.append(line.strip())\n",
    "                elif \"Priority\" in line or \"Estimated Timeline\" in line:\n",
    "                    highlights.append(line.strip())\n",
    "        return highlights\n",
    "\n",
    "    def generate_review_report(self, highlights):\n",
    "        \"\"\"\n",
    "        Create a review report for stakeholders.\n",
    "        \"\"\"\n",
    "        report = [\"# Action Plan Review Report\\n\"]\n",
    "        report.append(\"## Highlights\\n\")\n",
    "        report.extend([f\"- {highlight}\\n\" for highlight in highlights])\n",
    "\n",
    "        report.append(\"\\n## Key Questions\\n\")\n",
    "        report.append(\"- Are the proposed use cases aligned with company goals?\\n\")\n",
    "        report.append(\"- Are the timelines realistic?\\n\")\n",
    "        report.append(\"- Are the resources appropriate for implementation?\\n\")\n",
    "\n",
    "        report.append(\"\\n## Areas Requiring Feedback\\n\")\n",
    "        report.append(\"- Suggestions for prioritizing use cases.\\n\")\n",
    "        report.append(\"- Additional resources or tools to consider.\\n\")\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the previously generated action plan file\n",
    "    action_plan_file = \"action_plan.md\"\n",
    "\n",
    "    # Initialize the review report generator\n",
    "    review_generator = ReviewReportGenerator(action_plan_file)\n",
    "\n",
    "    # Extract highlights\n",
    "    highlights = review_generator.extract_highlights()\n",
    "\n",
    "    # Generate the review report\n",
    "    review_report = review_generator.generate_review_report(highlights)\n",
    "\n",
    "    # Save the review report to a markdown file\n",
    "    with open(\"review_report.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(review_report)\n",
    "\n",
    "    print(\"Review report saved to review_report.md\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
